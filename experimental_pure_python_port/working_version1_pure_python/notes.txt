This is the latest draft of a port of HLSVDPRO to Python. In keeping with my intention to "port it like an onion", I started by removing the first two layers. http://scion.duhs.duke.edu/vespa/analysis/wiki/HlsvdPorting

All Fortran files have been ported with two exceptions (see below). 

== Caveats ==

1) There's a small block of code at the end of zlansvdw.f that I didn't port. It's only activated if the input param jobv == 'Y' and it's hardcoded to 'N' in this code. It's just a single call to zgemmina() so if I debug that properly, porting this last call shouldn't be difficult.

2) There's no numpy entry point for the LAPACK function dbdsqr() and it's too complex to be worth re-writing in Python. I'm currently using the version inside the HLSVDPRO library but obviously any binary dependency defeats the main purpose of porting to Python. I'm still trying to figure out how to deal with this.

http://www.netlib.org/lapack/double/dbdsqr.f

== Results ==

Results match the Fortran code for all of the press_cpX files. laser_2010102901.xml goes badly. There's still some bugs in the Python to be worked out, apparently.


== Code Organization ==

My Python code is at the top level. The directory 'original' contains source and test files copied from vespa/hlsvd. I've modified the Fortran source to provide a new entry points, a bug fix (see below), and a bazillion print statements to check equivalence with my Python code.

== Performance ==
Performance is bad; I'm not worried about it yet. 

== Quality ==
My code is completely unoptimized, wildly messy by any standard and overrun with FIXMEs.



== Next Steps ==

My next steps are to  --
- Fix the bugs that cause laser_2010102901.xml to fail
- Improve performance which is quite bad
- Figure out how  to eliminate the dependency on dbdsqr()



===========================================================
maybe something promising ... ?

March 20, 2020 - Brian J Soher
Found at: https://gist.github.com/insertinterestingnamehere/b50390fc720e1e554af0


call_dgemm.py
----------------------------
# This shows how to use SciPy's Cython-exposure of the BLAS and LAPACK libraries from within ctypes

Here's the doc entry on BLAS DGEMM

 NAME
      DGEMM - perform one of the matrix-matrix operations   C :=
      alpha*op( A )*op( B ) + beta*C,

 SYNOPSIS
      SUBROUTINE DGEMM ( TRANSA, TRANSB, M, N, K, ALPHA, A, LDA,
                       B, LDB, BETA, C, LDC )

          CHARACTER*1  TRANSA, TRANSB

          INTEGER      M, N, K, LDA, LDB, LDC

          DOUBLE       PRECISION ALPHA, BETA

          DOUBLE       PRECISION A( LDA, * ), B( LDB, * ), C( LDC,
                       * )

 PURPOSE
      DGEMM  performs one of the matrix-matrix operations

      where  op( X ) is one of

         op( X ) = X   or   op( X ) = X',

      alpha and beta are scalars, and A, B and C are matrices,
      with op( A ) an m by k matrix,  op( B )  a  k by n matrix
      and  C an m by n matrix.


--------------------------------
import numpy as np
import ctypes as ct
from scipy.linalg import cython_blas

#ct.cdll.LoadLibrary("libopenblas.dll")
#openblas = ct.CDLL("libopenblas.dll")
#dgemm = openblas.dgemm

ct.pythonapi.PyCapsule_GetPointer.restype = ct.c_void_p
ct.pythonapi.PyCapsule_GetPointer.argtypes = [ct.py_object, ct.c_char_p]
ct.pythonapi.PyCapsule_GetName.restype = ct.c_char_p
ct.pythonapi.PyCapsule_GetName.argtypes = [ct.py_object]
ptr_type = ct.CFUNCTYPE(ct.c_void_p, ct.c_char_p, ct.c_char_p,
                        ct.POINTER(ct.c_int), ct.POINTER(ct.c_int),
                        ct.POINTER(ct.c_int), ct.POINTER(ct.c_double),
                        ct.POINTER(ct.c_double), ct.POINTER(ct.c_int),
                        ct.POINTER(ct.c_double), ct.POINTER(ct.c_int),
                        ct.POINTER(ct.c_double), ct.POINTER(ct.c_double),
                        ct.POINTER(ct.c_int))
dgemm2 = ptr_type(
             ct.pythonapi.PyCapsule_GetPointer(
                 cython_blas.__pyx_capi__['dgemm'],
                 ct.pythonapi.PyCapsule_GetName(
                     cython_blas.__pyx_capi__['dgemm'])))

a = np.array([[1,2],[3,4]], 'd', order='F')
b = np.array([[5,6],[7,8]], 'd', order='F')
c = np.empty((2,2), order='F')

transa = ct.c_char('N')
transb = ct.c_char('N')
alpha = ct.c_double(1.)
beta = ct.c_double(0.)
lda = ct.c_int(2)
ldb = ct.c_int(2)
ldc = ct.c_int(2)
m = ct.c_int(2)
n = ct.c_int(2)
k = ct.c_int(2)
args = (ct.byref(transa), ct.byref(transb), ct.byref(m), ct.byref(n),
        ct.byref(k), ct.byref(alpha),
        a.ctypes.data_as(ct.POINTER(ct.c_double)), ct.byref(lda),
        b.ctypes.data_as(ct.POINTER(ct.c_double)), ct.byref(ldb),
        ct.byref(beta), c.ctypes.data_as(ct.POINTER(ct.c_double)),
        ct.byref(ldc))
#dgemm(*args)
#print c
c[:] = 0
dgemm2(*args)
print c
print a.dot(b)

#--------------------------------------------
HEre is a C example for using DGEMM
#--------------------------------------------

/* C source code is found in dgemm_example.c */

#define min(x,y) (((x) < (y)) ? (x) : (y))

#include <stdio.h>
#include <stdlib.h>
#include "mkl.h"

int main()
{
    double *A, *B, *C;
    int m, n, k, i, j;
    double alpha, beta;

    printf ("\n This example computes real matrix C=alpha*A*B+beta*C using \n"
            " Intel(R) MKL function dgemm, where A, B, and  C are matrices and \n"
            " alpha and beta are double precision scalars\n\n");

    m = 2000, k = 200, n = 1000;
    printf (" Initializing data for matrix multiplication C=A*B for matrix \n"
            " A(%ix%i) and matrix B(%ix%i)\n\n", m, k, k, n);
    alpha = 1.0; beta = 0.0;

    printf (" Allocating memory for matrices aligned on 64-byte boundary for better \n"
            " performance \n\n");
    A = (double *)mkl_malloc( m*k*sizeof( double ), 64 );
    B = (double *)mkl_malloc( k*n*sizeof( double ), 64 );
    C = (double *)mkl_malloc( m*n*sizeof( double ), 64 );
    if (A == NULL || B == NULL || C == NULL) {
      printf( "\n ERROR: Can't allocate memory for matrices. Aborting... \n\n");
      mkl_free(A);
      mkl_free(B);
      mkl_free(C);
      return 1;
    }

    printf (" Intializing matrix data \n\n");
    for (i = 0; i < (m*k); i++) {
        A[i] = (double)(i+1);
    }

    for (i = 0; i < (k*n); i++) {
        B[i] = (double)(-i-1);
    }

    for (i = 0; i < (m*n); i++) {
        C[i] = 0.0;
    }

    printf (" Computing matrix product using Intel(R) MKL dgemm function via CBLAS interface \n\n");
    cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 
                m, n, k, alpha, A, k, B, n, beta, C, n);
    printf ("\n Computations completed.\n\n");

    printf (" Top left corner of matrix A: \n");
    for (i=0; i<min(m,6); i++) {
      for (j=0; j<min(k,6); j++) {
        printf ("%12.0f", A[j+i*k]);
      }
      printf ("\n");
    }

    printf ("\n Top left corner of matrix B: \n");
    for (i=0; i<min(k,6); i++) {
      for (j=0; j<min(n,6); j++) {
        printf ("%12.0f", B[j+i*n]);
      }
      printf ("\n");
    }
    
    printf ("\n Top left corner of matrix C: \n");
    for (i=0; i<min(m,6); i++) {
      for (j=0; j<min(n,6); j++) {
        printf ("%12.5G", C[j+i*n]);
      }
      printf ("\n");
    }

    printf ("\n Deallocating memory \n\n");
    mkl_free(A);
    mkl_free(B);
    mkl_free(C);

    printf (" Example completed. \n\n");
    return 0;
}



