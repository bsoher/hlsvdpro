# Python modules
from __future__ import division
import pdb

# 3rd party modules
import numpy as np
import scipy
import scipy.linalg.blas

# Our modules
import aprodw
import zreorth


KAPPA = 0.717

USE_FORTRAN_RANDOMS = False


# Float BLAS functions
dznrm2, = scipy.linalg.blas.get_blas_funcs( ['znrm2'], np.array([0.0]) )



def _get_predictable_randoms(size):
    """
    Given an array size, reads from the file first_random.txt and turns the 
    values therein into a complex array of length size. The array is returned.
    
    """
    lines = open('first_random.txt').read().split('\n')
    lines = [ 'complex' + line for line in lines]
    lines = map(eval, lines)
    lines = lines[:size]
    
    return np.array(lines)
 



# Variable name translations 
# Fortran    Python             Description
# -------    ------             -------------------------------------------
# icgs       classical_gs       > 0 or True ==> use classical Gram-Schmidt,
#                               otherwise use modified Gram-Schmidt. No 
#                               relation to Mason Williams' Classical Gas.



def zgetu0w(transa, ndp, m, n, j, ntry, u0, uuu, classical_gs, lambda_, trlambda):

    transa = transa.lower()
    if transa == 'n':
        rsize = n
        usize = m
    else:
        rsize = m
        usize = n

    # PS idist == 2 implies uniform distribution when generating random numbers. 
    ierr = 0

    zwork1 = np.zeros( (ndp, ), np.complex128)
    zwork2 = np.zeros( (ndp, ), np.complex128)

    set_ierr = True
    for itry in range(ntry):

        # PS Here we want to generate some random numbers. The random numbers 
        # generated by the Fortran code are random, but predictably so. The 
        # RNG is passed a seed that's limited to one of a few primes. As a 
        # result, it always generates the same sets of random numbers. I 
        # don't know why it's coded this way.
        # For debugging, I wrote the first set of random numbers to disk in 
        # the file first_random.txt, and if I want my Python code to use the
        # same exact set of "random" numbers I set USE_FORTRAN_RANDOMS to
        # True.
        # In practice, I leave that flag False. That makes the code faster and
        # maybe more robust.

        if USE_FORTRAN_RANDOMS:
            zworkr = _get_predictable_randoms(rsize)
        else:
            reals = np.random.uniform(-1.0, 1.0, rsize)
            imags = np.random.uniform(-1.0, 1.0, rsize)
            zworkr = np.array( [complex(r, i) for r, i in zip(reals, imags)] )

        # BJS replace with scipy.linalg.blas.dznrm2
        nrm = dznrm2(zworkr)
        #nrm = scipy.linalg.norm(zworkr)

        zworkr, u0, zwork1, zwork2 = aprodw.aprodw(transa, ndp, m, n, 
                                                   zworkr, u0, zwork1, zwork2,
                                                   lambda_, trlambda)

        # BJS replace with scipy.linalg.blas.dznrm2
        u0norm = dznrm2(u0)
        #u0norm = scipy.linalg.norm(u0)

        anormest = u0norm / nrm

        index = [1, j, j + 1]

        # PS - MGS and icgs both refer to the same thing. zreorth() can perform
        # classical or modified Gram-Schmidt orthogonalization. In some version
        # of the Fortran code, this was controlled by MGS, but that's commented
        # out in the version of the code we have. 
        # Instead, its controlled by icgs. 
        # icgs ==> non-zero (True) to tell zreorth to use classical Gram-Schmidt,
        #          False to use modified Gram-Schmidt.
        # In the version of the code we have, it's hardcoded to 1 so we always
        # use classical Gram-Schmidt.

        u0, u0norm = zreorth.zreorth(usize, j, uuu, u0, u0norm, index, KAPPA, classical_gs)

        if u0norm > 0:
            set_ierr = False
            break

    if set_ierr:
        ierr = -1
        
    return u0norm, anormest, ierr
